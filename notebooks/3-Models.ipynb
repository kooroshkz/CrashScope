{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87655f47",
   "metadata": {},
   "source": [
    "# Machine Learning Models\n",
    "\n",
    "Training three classification models for crash prediction API:\n",
    "1. **Severity Predictor** -> Classifies accidents as Fatal/Injury/Property damage\n",
    "2. **Accident Type Classifier** -> Predicts crash type like collision, single-vehicle and pedestrian\n",
    "3. **Location Risk Assessor** -> Determines urban vs outisde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "003ed6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/19 16:05:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/11/19 16:05:20 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 190,829\n",
      "Test samples: 47,696\n",
      "Features: 33\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark and load preprocessed data\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pathlib import Path\n",
    "\n",
    "PROCESSED_DIR = Path(\"../datasets/ProcessedData\")\n",
    "\n",
    "spark = SparkSession.builder.appName(\"CrashScope-Models\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "# Load preprocessed data\n",
    "train_df = spark.read.parquet(str(PROCESSED_DIR / \"train.parquet\"))\n",
    "test_df = spark.read.parquet(str(PROCESSED_DIR / \"test.parquet\"))\n",
    "\n",
    "print(f\"Training samples: {train_df.count():,}\")\n",
    "print(f\"Test samples: {test_df.count():,}\")\n",
    "print(f\"Features: {len(train_df.select('features').first().features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ebe4af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target encoders fitted successfully\n",
      "Severity: 3 classes\n",
      "Type: 10 classes\n",
      "Location: 2 classes\n"
     ]
    }
   ],
   "source": [
    "# Create target encoders for all prediction tasks\n",
    "target_encoders = {\n",
    "    'severity': StringIndexer(inputCol=\"verkeersongeval_afloop\", outputCol=\"severity_label\"),\n",
    "    'type': StringIndexer(inputCol=\"aard_ongeval\", outputCol=\"type_label\"),\n",
    "    'location': StringIndexer(inputCol=\"bebouwde_kom\", outputCol=\"location_label\")\n",
    "}\n",
    "\n",
    "# Fit encoders\n",
    "fitted_encoders = {name: encoder.fit(train_df) for name, encoder in target_encoders.items()}\n",
    "\n",
    "print(\"Target encoders fitted successfully\")\n",
    "for name, encoder in fitted_encoders.items():\n",
    "    labels = encoder.labels\n",
    "    print(f\"{name.title()}: {len(labels)} classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f386b7dd",
   "metadata": {},
   "source": [
    "# MODEL 1: Accident Severity Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e25b35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Severity Prediction Results:\n",
      "Random Forest Accuracy: 0.9977\n",
      "Logistic Regression Accuracy: 1.0000\n",
      "Best Model: LogisticRegression (Accuracy: 1.0000)\n"
     ]
    }
   ],
   "source": [
    "# Prepare severity data\n",
    "train_severity = fitted_encoders['severity'].transform(train_df)\n",
    "test_severity = fitted_encoders['severity'].transform(test_df)\n",
    "\n",
    "# Train models\n",
    "rf_severity = RandomForestClassifier(featuresCol=\"features\", labelCol=\"severity_label\", numTrees=50)\n",
    "lr_severity = LogisticRegression(featuresCol=\"features\", labelCol=\"severity_label\", maxIter=50)\n",
    "\n",
    "rf_severity_model = rf_severity.fit(train_severity)\n",
    "lr_severity_model = lr_severity.fit(train_severity)\n",
    "\n",
    "# Evaluate models\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"severity_label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "rf_severity_pred = rf_severity_model.transform(test_severity)\n",
    "lr_severity_pred = lr_severity_model.transform(test_severity)\n",
    "\n",
    "rf_accuracy = evaluator.evaluate(rf_severity_pred)\n",
    "lr_accuracy = evaluator.evaluate(lr_severity_pred)\n",
    "\n",
    "print(f\"Severity Prediction Results:\")\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")\n",
    "print(f\"Logistic Regression Accuracy: {lr_accuracy:.4f}\")\n",
    "\n",
    "# Select best model\n",
    "best_severity_model = rf_severity_model if rf_accuracy >= lr_accuracy else lr_severity_model\n",
    "best_severity_name = \"RandomForest\" if rf_accuracy >= lr_accuracy else \"LogisticRegression\"\n",
    "best_severity_accuracy = max(rf_accuracy, lr_accuracy)\n",
    "\n",
    "print(f\"Best Model: {best_severity_name} (Accuracy: {best_severity_accuracy:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0611aa4c",
   "metadata": {},
   "source": [
    "# MODEL 2: Accident Type Classification  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e6c2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accident Type Prediction Results:\n",
      "Random Forest Accuracy: 0.9942\n",
      "Logistic Regression Accuracy: 1.0000\n",
      "Best Model: LogisticRegression (Accuracy: 1.0000)\n"
     ]
    }
   ],
   "source": [
    "# Prepare accident type data\n",
    "train_type = fitted_encoders['type'].transform(train_df)\n",
    "test_type = fitted_encoders['type'].transform(test_df)\n",
    "\n",
    "# Train models\n",
    "rf_type = RandomForestClassifier(featuresCol=\"features\", labelCol=\"type_label\", numTrees=50)\n",
    "lr_type = LogisticRegression(featuresCol=\"features\", labelCol=\"type_label\", maxIter=50)\n",
    "\n",
    "rf_type_model = rf_type.fit(train_type)\n",
    "lr_type_model = lr_type.fit(train_type)\n",
    "\n",
    "# Evaluate models\n",
    "type_evaluator = MulticlassClassificationEvaluator(labelCol=\"type_label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "rf_type_pred = rf_type_model.transform(test_type)\n",
    "lr_type_pred = lr_type_model.transform(test_type)\n",
    "\n",
    "rf_type_accuracy = type_evaluator.evaluate(rf_type_pred)\n",
    "lr_type_accuracy = type_evaluator.evaluate(lr_type_pred)\n",
    "\n",
    "print(f\"Accident Type Prediction Results:\")\n",
    "print(f\"Random Forest Accuracy: {rf_type_accuracy:.4f}\")\n",
    "print(f\"Logistic Regression Accuracy: {lr_type_accuracy:.4f}\")\n",
    "\n",
    "# Select best model\n",
    "best_type_model = rf_type_model if rf_type_accuracy >= lr_type_accuracy else lr_type_model\n",
    "best_type_name = \"RandomForest\" if rf_type_accuracy >= lr_type_accuracy else \"LogisticRegression\"\n",
    "best_type_accuracy = max(rf_type_accuracy, lr_type_accuracy)\n",
    "\n",
    "print(f\"Best Model: {best_type_name} (Accuracy: {best_type_accuracy:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9352f835",
   "metadata": {},
   "source": [
    "# MODEL 3: Location Risk Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fd0cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location Risk Assessment Results:\n",
      "Random Forest Accuracy: 1.0000\n",
      "Logistic Regression Accuracy: 1.0000\n",
      "Best Model: RandomForest (Accuracy: 1.0000)\n"
     ]
    }
   ],
   "source": [
    "# Prepare location data\n",
    "train_location = fitted_encoders['location'].transform(train_df)\n",
    "test_location = fitted_encoders['location'].transform(test_df)\n",
    "\n",
    "# Train models\n",
    "rf_location = RandomForestClassifier(featuresCol=\"features\", labelCol=\"location_label\", numTrees=50)\n",
    "lr_location = LogisticRegression(featuresCol=\"features\", labelCol=\"location_label\", maxIter=50)\n",
    "\n",
    "rf_location_model = rf_location.fit(train_location)\n",
    "lr_location_model = lr_location.fit(train_location)\n",
    "\n",
    "# Evaluate models\n",
    "location_evaluator = MulticlassClassificationEvaluator(labelCol=\"location_label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "rf_location_pred = rf_location_model.transform(test_location)\n",
    "lr_location_pred = lr_location_model.transform(test_location)\n",
    "\n",
    "rf_location_accuracy = location_evaluator.evaluate(rf_location_pred)\n",
    "lr_location_accuracy = location_evaluator.evaluate(lr_location_pred)\n",
    "\n",
    "print(f\"Location Risk Assessment Results:\")\n",
    "print(f\"Random Forest Accuracy: {rf_location_accuracy:.4f}\")\n",
    "print(f\"Logistic Regression Accuracy: {lr_location_accuracy:.4f}\")\n",
    "\n",
    "# Select best model\n",
    "best_location_model = rf_location_model if rf_location_accuracy >= lr_location_accuracy else lr_location_model\n",
    "best_location_name = \"RandomForest\" if rf_location_accuracy >= lr_location_accuracy else \"LogisticRegression\"\n",
    "best_location_accuracy = max(rf_location_accuracy, lr_location_accuracy)\n",
    "\n",
    "print(f\"Best Model: {best_location_name} (Accuracy: {best_location_accuracy:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5708774",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "576b0652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CRASHSCOPE MODEL PERFORMANCE SUMMARY ===\n",
      "Dataset: 190,829 training, 47,696 test samples\n",
      "Features: 33\n",
      "\n",
      "Model Accuracies:\n",
      "1. Severity Predictor (LogisticRegression): 1.0000\n",
      "2. Accident Type (LogisticRegression): 1.0000\n",
      "3. Location Risk (RandomForest): 1.0000\n",
      "\n",
      "Models saved successfully to ../models/\n",
      "Ready for API deployment\n"
     ]
    }
   ],
   "source": [
    "# Model Performance Summary and Save\n",
    "print(\"=== CRASHSCOPE MODEL PERFORMANCE SUMMARY ===\")\n",
    "print(f\"Dataset: {train_df.count():,} training, {test_df.count():,} test samples\")\n",
    "print(f\"Features: {len(train_df.select('features').first().features)}\")\n",
    "print(\"\\nModel Accuracies:\")\n",
    "print(f\"1. Severity Predictor ({best_severity_name}): {best_severity_accuracy:.4f}\")\n",
    "print(f\"2. Accident Type ({best_type_name}): {best_type_accuracy:.4f}\")\n",
    "print(f\"3. Location Risk ({best_location_name}): {best_location_accuracy:.4f}\")\n",
    "\n",
    "# Save models for deployment\n",
    "import os\n",
    "model_dir = \"../models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "best_severity_model.write().overwrite().save(f\"{model_dir}/severity_model\")\n",
    "best_type_model.write().overwrite().save(f\"{model_dir}/accident_type_model\")\n",
    "best_location_model.write().overwrite().save(f\"{model_dir}/location_risk_model\")\n",
    "\n",
    "fitted_encoders['severity'].write().overwrite().save(f\"{model_dir}/severity_indexer\")\n",
    "fitted_encoders['type'].write().overwrite().save(f\"{model_dir}/type_indexer\")\n",
    "fitted_encoders['location'].write().overwrite().save(f\"{model_dir}/location_indexer\")\n",
    "\n",
    "print(\"\\nModels saved successfully to ../models/\")\n",
    "print(\"Ready for API deployment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec18cf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Prediction:\n",
      "+----------------------+------------+------------+----------------+----------------+\n",
      "|verkeersongeval_afloop|aard_ongeval|bebouwde_kom|weersgesteldheid|maximum_snelheid|\n",
      "+----------------------+------------+------------+----------------+----------------+\n",
      "|                Letsel|   Eenzijdig|      Binnen|           Droog|            15.0|\n",
      "+----------------------+------------+------------+----------------+----------------+\n",
      "\n",
      "Predicted Severity: Letsel\n",
      "Predicted Type: Eenzijdig\n",
      "Predicted Location: Binnen\n",
      "\n",
      "Spark session closed\n"
     ]
    }
   ],
   "source": [
    "# Prediction Example\n",
    "example = test_df.limit(1)\n",
    "print(\"Sample Prediction:\")\n",
    "example.select(\"verkeersongeval_afloop\", \"aard_ongeval\", \"bebouwde_kom\", \n",
    "               \"weersgesteldheid\", \"maximum_snelheid\").show()\n",
    "\n",
    "# Apply all models\n",
    "severity_pred = best_severity_model.transform(fitted_encoders['severity'].transform(example))\n",
    "type_pred = best_type_model.transform(fitted_encoders['type'].transform(example))\n",
    "location_pred = best_location_model.transform(fitted_encoders['location'].transform(example))\n",
    "\n",
    "severity_result = severity_pred.select(\"prediction\").collect()[0][0]\n",
    "type_result = type_pred.select(\"prediction\").collect()[0][0]\n",
    "location_result = location_pred.select(\"prediction\").collect()[0][0]\n",
    "\n",
    "# Map predictions to labels\n",
    "severity_labels = fitted_encoders['severity'].labels\n",
    "type_labels = fitted_encoders['type'].labels\n",
    "location_labels = fitted_encoders['location'].labels\n",
    "\n",
    "print(f\"Predicted Severity: {severity_labels[int(severity_result)]}\")\n",
    "print(f\"Predicted Type: {type_labels[int(type_result)]}\")\n",
    "print(f\"Predicted Location: {location_labels[int(location_result)]}\")\n",
    "\n",
    "# Clean up\n",
    "spark.stop()\n",
    "print(\"\\nSpark session closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
